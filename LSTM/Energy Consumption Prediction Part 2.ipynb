{"cells":[{"cell_type":"markdown","metadata":{"id":"qXlm45Z9OJH0"},"source":["We will use GRU and LSTM models for a time series prediction job, and we will compare the GRU model's performance to that of an LSTM model. The purpose of this implementation is to **create a model that can reliably anticipate energy use in the following hour**"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7116,"status":"ok","timestamp":1712797843212,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"},"user_tz":-420},"id":"k5yJ3PFkOJH2"},"outputs":[],"source":["import os\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","from tqdm.notebook import tqdm as tqdm_notebook\n","from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"markdown","metadata":{"id":"oxmJvwYcOJH2"},"source":["# **Load Dataset**"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":4603,"status":"ok","timestamp":1712797847811,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"},"user_tz":-420},"id":"d0omygfBOJH2","outputId":"84db5e14-a2db-42c2-b840-2201d6da3dc6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["              Datetime  DEOK_MW\n","0  2012-12-31 01:00:00   2945.0\n","1  2012-12-31 02:00:00   2868.0\n","2  2012-12-31 03:00:00   2812.0\n","3  2012-12-31 04:00:00   2812.0\n","4  2012-12-31 05:00:00   2860.0"],"text/html":["\n","  <div id=\"df-408a5a73-33b8-4de7-b66f-083d76589e7b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Datetime</th>\n","      <th>DEOK_MW</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2012-12-31 01:00:00</td>\n","      <td>2945.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2012-12-31 02:00:00</td>\n","      <td>2868.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2012-12-31 03:00:00</td>\n","      <td>2812.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2012-12-31 04:00:00</td>\n","      <td>2812.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2012-12-31 05:00:00</td>\n","      <td>2860.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-408a5a73-33b8-4de7-b66f-083d76589e7b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-408a5a73-33b8-4de7-b66f-083d76589e7b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-408a5a73-33b8-4de7-b66f-083d76589e7b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7357288e-940c-48b6-bd5c-53e22b56a885\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7357288e-940c-48b6-bd5c-53e22b56a885')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7357288e-940c-48b6-bd5c-53e22b56a885 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df4","summary":"{\n  \"name\": \"df4\",\n  \"rows\": 57739,\n  \"fields\": [\n    {\n      \"column\": \"Datetime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 57735,\n        \"samples\": [\n          \"2016-07-21 12:00:00\",\n          \"2014-04-05 18:00:00\",\n          \"2018-05-24 16:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DEOK_MW\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 599.8590256850771,\n        \"min\": 907.0,\n        \"max\": 5445.0,\n        \"num_unique_values\": 3192,\n        \"samples\": [\n          2886.0,\n          2643.0,\n          3071.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":2}],"source":["dataset1 = 'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/AEP_hourly.csv'\n","dataset2 = 'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/COMED_hourly.csv'\n","dataset3 = 'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/DAYTON_hourly.csv'\n","dataset4 = 'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/DEOK_hourly.csv'\n","dataset5 = 'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/DOM_hourly.csv'\n","dataset6 = 'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/DUQ_hourly.csv'\n","dataset7 = 'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/EKPC_hourly.csv'\n","dataset8 = 'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/FE_hourly.csv'\n","dataset8 = 'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/NI_hourly.csv'\n","dataset9 = 'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/PJME_hourly.csv'\n","dataset10 = 'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/PJMW_hourly.csv'\n","dataset11 = 'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/PJM_Load_hourly.csv'\n","\n","# Load each dataset\n","df1 = pd.read_csv(dataset1)\n","df2 = pd.read_csv(dataset2)\n","df3 = pd.read_csv(dataset3)\n","df4 = pd.read_csv(dataset4)\n","df5 = pd.read_csv(dataset5)\n","df6 = pd.read_csv(dataset6)\n","df7 = pd.read_csv(dataset7)\n","df8 = pd.read_csv(dataset8)\n","df9 = pd.read_csv(dataset9)\n","df10 = pd.read_csv(dataset10)\n","df11 = pd.read_csv(dataset11)\n","\n","# Concatenate the datasets\n","# merged_df = pd.concat([df1, df2, df3, df4, df5])\n","\n","# Display the merged DataFrame\n","df4.head()\n"]},{"cell_type":"markdown","metadata":{"id":"Uo2c8W0POJH3"},"source":["**format dataset time**\n","- Hour of the day *i.e. 0-23*\n","- Day of the week *i.e. 1-7*\n","- Month *i.e. 1-12*\n","- Day of the year *i.e. 1-365*\n","        \n","Group the data into sequences (**window_size period**) is the number of data points in history that the model will use to make the prediction\n","    "]},{"cell_type":"markdown","metadata":{"id":"JxDzQGWWOJH3"},"source":["# **Create training instances using sliding window**"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1712797847812,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"},"user_tz":-420},"id":"AjRkheh4OJH3"},"outputs":[],"source":["def move_sliding_window(data, window_size, inputs_cols_indices, label_col_index):\n","    # (# instances created by movement, seq_len (timestamps), # features (input_len))\n","    inputs = np.zeros((len(data) - window_size, window_size, len(inputs_cols_indices)))\n","    labels = np.zeros(len(data) - window_size)\n","\n","    for i in range(window_size, len(data)):\n","        inputs[i - window_size] = data[i - window_size : i, inputs_cols_indices]\n","        labels[i - window_size] = data[i, label_col_index]\n","    inputs = inputs.reshape(-1, window_size, len(inputs_cols_indices))\n","    labels = labels.reshape(-1, 1)\n","    print(inputs.shape, labels.shape)\n","\n","    return inputs, labels"]},{"cell_type":"markdown","metadata":{"id":"9pcA_iQaOJH3"},"source":["# **Build the Training Set**"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["ddc04c03ff4e4de7a40dd72f34038767","8bc8ab39374442f79af3b19ae78d5ef1","9ba64a65a8254c1f963b009e26df8b53","4c0fc8a3e8034da0893c61cc079a9876","3dcdfd7cc5a747d092e138b507deb73f","23eda55a86eb4aeebd2f0ac5ba958bda","ec113ca6eca44a2686f42a4dfdd7a61f","2085b993975b43f78679b984709fc531","b873635ef01a4f418c75de31754dd5c4","2be872a600ca40af96c9c094d0cac129","a0c4f61fefba4d4293a8b2dd159dfa1a"]},"executionInfo":{"elapsed":41041,"status":"ok","timestamp":1712797888820,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"},"user_tz":-420},"id":"3XapyCVvy_tp","outputId":"a084cfac-8e68-4d1b-da0e-cbf2dfd283a2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddc04c03ff4e4de7a40dd72f34038767"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/AEP_hourly.csv ...\n","Processing https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/COMED_hourly.csv ...\n","Processing https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/DAYTON_hourly.csv ...\n","Processing https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/DEOK_hourly.csv ...\n","Processing https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/DOM_hourly.csv ...\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from tqdm.notebook import tqdm_notebook\n","import requests\n","from io import StringIO\n","\n","# Definisi fungsi move_sliding_window\n","def move_sliding_window(data, window_size, inputs_cols_indices, label_col_index):\n","    inputs = []\n","    labels = []\n","    for i in range(len(data) - window_size):\n","        inputs.append(data[i:i + window_size, inputs_cols_indices])\n","        labels.append(data[i + window_size, label_col_index])\n","    return np.array(inputs), np.array(labels)\n","\n","# Definisi variabel label_col_index, inputs_cols_indices, window_size\n","label_col_index = 0  # consumption as label to predict\n","inputs_cols_indices = range(5)  # use (consumption, hour, dayofweek, month, dayofyear) columns as features\n","window_size = 90\n","\n","# Definisi variabel train_x, test_x, test_y\n","label_scalers = {}\n","train_x = []\n","test_x = {}\n","test_y = {}\n","\n","# URL dataset\n","dataset_urls = [\n","    'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/AEP_hourly.csv',\n","    'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/COMED_hourly.csv',\n","    'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/DAYTON_hourly.csv',\n","    'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/DEOK_hourly.csv',\n","    'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/PrediksiEnergi/data/DOM_hourly.csv'\n","]\n","\n","num_files_for_dataset = 5\n","\n","for url in tqdm_notebook(dataset_urls[:num_files_for_dataset]):\n","    print(f\"Processing {url} ...\")\n","    # Mengunduh file CSV\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        # Membaca file CSV ke dalam DataFrame Pandas\n","        df = pd.read_csv(StringIO(response.text), parse_dates=[\"Datetime\"])\n","\n","        # Memproses data waktu menjadi format yang sesuai untuk input\n","        df[\"hour\"] = df.apply(lambda x: x[\"Datetime\"].hour, axis=1)\n","        df[\"dayofweek\"] = df.apply(lambda x: x[\"Datetime\"].dayofweek, axis=1)\n","        df[\"month\"] = df.apply(lambda x: x[\"Datetime\"].month, axis=1)\n","        df[\"dayofyear\"] = df.apply(lambda x: x[\"Datetime\"].dayofyear, axis=1)\n","        df = df.sort_values(\"Datetime\").drop(\"Datetime\", axis=1)\n","\n","        # Melakukan penskalaan pada data input\n","        sc = MinMaxScaler()\n","        label_sc = MinMaxScaler()\n","        data = sc.fit_transform(df.values)\n","\n","        # Mendapatkan objek penskalaan untuk label (data penggunaan) agar output dapat diubah kembali ke nilai aktual selama evaluasi\n","        label_sc.fit(df.iloc[:, label_col_index].values.reshape(-1, 1))\n","        label_scalers[url] = label_sc\n","\n","        # Memindahkan jendela\n","        inputs, labels = move_sliding_window(\n","            data,\n","            window_size,\n","            inputs_cols_indices=inputs_cols_indices,\n","            label_col_index=label_col_index,\n","        )\n","\n","        # Menggabungkan data dari semua file .csv\n","        test_portion = int(0.1 * len(inputs))\n","        if len(train_x) == 0:  # iterasi pertama\n","            train_x = inputs[:-test_portion]\n","            train_y = labels[:-test_portion]\n","        else:\n","            train_x = np.concatenate((train_x, inputs[:-test_portion]))\n","            train_y = np.concatenate((train_y, labels[:-test_portion]))\n","        test_x[url] = inputs[-test_portion:]\n","        test_y[url] = labels[-test_portion:]\n","    else:\n","        print(f\"Failed to download {url}\")"]},{"cell_type":"markdown","metadata":{"id":"AgiWpbFWOJH3"},"source":["# **Pytorch Data Loaders**"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":778,"status":"ok","timestamp":1712797889578,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"},"user_tz":-420},"id":"VDYoGfYG1ICh","outputId":"e28a138d-f9c9-4059-cc83-b62ed7173ca2"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([90, 5])\n","torch.Size([])\n"]}],"source":["import numpy as np\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# Konversi train_x dan train_y menjadi numpy array\n","train_x = np.array(train_x)\n","train_y = np.array(train_y)\n","\n","# Buat TensorDataset dari numpy array\n","train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n","\n","# Cetak ukuran tensor dari input pertama dan label pertama\n","print(train_data[0][0].shape)  # Cetak ukuran tensor dari input pertama\n","print(train_data[0][1].shape)  # Cetak ukuran tensor dari label pertama"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":524,"status":"ok","timestamp":1712797890095,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"},"user_tz":-420},"id":"dbgyEE8_OJH4"},"outputs":[],"source":["batch_size = 1024\n","\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# Konversi train_x dan train_y menjadi numpy array\n","train_x = np.array(train_x)\n","train_y = np.array(train_y)\n","\n","# Buat TensorDataset dari numpy array\n","train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n","\n","# Drop the last incomplete batch\n","train_loader = DataLoader(\n","    train_data, shuffle=True, batch_size=batch_size, drop_last=True\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1712797890095,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"},"user_tz":-420},"id":"CfyZxfxvOJH4","outputId":"4cfb478c-7c4b-4fa5-f068-186832fc7b6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Size: (434274, 90, 5), Batch Size: 1024, # of iterations per epoch: 424\n"]}],"source":["print(\n","    f\"Train Size: {train_x.shape}, Batch Size: {batch_size}, # of iterations per epoch: {int(train_x.shape[0]/batch_size)}\"\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1712797890095,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"},"user_tz":-420},"id":"3LOdrDgHOJH4"},"outputs":[],"source":["# release some memory\n","del train_x, train_y"]},{"cell_type":"markdown","metadata":{"id":"mgc8YOh-OJH4"},"source":["We can also check if we have any GPUs to speed up our training time by many folds. If you’re using \"https://colab.research.google.com/\" with GPU to run this code, the training time will be significantly reduced."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1712797890096,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"},"user_tz":-420},"id":"VNCraTpWOJH4"},"outputs":[],"source":["# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n","is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1712797890096,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"},"user_tz":-420},"id":"ji0uXDtEOJH4"},"outputs":[],"source":["class GRUNet(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n","        super(GRUNet, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.n_layers = n_layers\n","\n","        self.gru = nn.GRU(\n","            input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob\n","        )\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x, h):\n","        out, h = self.gru(x, h)\n","        # print(out[:, -1].shape, h.shape)\n","        # select hidden state of last timestamp (t=90) (1024, 256)\n","        out = self.fc(self.relu(out[:, -1]))  # out[:, -1, :]\n","        # print(out.shape) # (1024, 1)\n","        return out, h\n","\n","    def init_hidden(self, batch_size):\n","        # Initialze h_0 with zeros\n","        weight = next(self.parameters()).data\n","        hidden = (\n","            weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n","        )\n","        return hidden\n","\n","\n","class LSTMNet(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n","        super(LSTMNet, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.n_layers = n_layers\n","\n","        self.lstm = nn.LSTM(\n","            input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob\n","        )\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x, h):\n","        out, h = self.lstm(x, h)\n","        out = self.fc(self.relu(out[:, -1]))\n","        return out, h\n","\n","    def init_hidden(self, batch_size):\n","        weight = next(self.parameters()).data\n","        # Initialze h_0, c_0 with zeros\n","        hidden = (\n","            weight.new(self.n_layers, batch_size, self.hidden_dim)\n","            .zero_()\n","            .to(device),  # h_0\n","            weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n","        )\n","        return hidden"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1712797890096,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"},"user_tz":-420},"id":"IHcyelGHOJH4"},"outputs":[],"source":["def train(\n","    train_loader,\n","    learn_rate,\n","    hidden_dim=256,\n","    n_layers=2,\n","    n_epochs=5,\n","    model_type=\"GRU\",\n","    print_every=100,\n","):\n","\n","    input_dim = next(iter(train_loader))[0].shape[2]  # 5\n","\n","    # Batch generator (train_data, train_label)\n","    # print(next(iter(train_loader))[0].shape, next(iter(train_loader))[1].shape) # torch.Size([1024, 90, 5]) torch.Size([1024, 1])\n","\n","    output_dim = 1\n","\n","    # Instantiating the models\n","    if model_type == \"GRU\":\n","        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n","    else:\n","        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n","    model.to(device)\n","\n","    # Defining loss function and optimizer\n","    criterion = nn.MSELoss()  # Mean Squared Error\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n","\n","    model.train()\n","    print(\"Starting Training of {} model\".format(model_type))\n","    epoch_times = []\n","\n","    # Start training loop\n","    for epoch in range(1, n_epochs + 1):\n","        start_time = time.process_time()\n","        h = model.init_hidden(batch_size)\n","        avg_loss = 0.0\n","        counter = 0\n","        for x, label in train_loader:\n","            counter += 1\n","            if model_type == \"GRU\":\n","                h = h.data\n","            # Unpcak both h_0 and c_0\n","            elif model_type == \"LSTM\":\n","                h = tuple([e.data for e in h])\n","\n","            # Set the gradients to zero before starting to do backpropragation because\n","            # PyTorch accumulates the gradients on subsequent backward passes\n","            model.zero_grad()\n","\n","            out, h = model(x.to(device).float(), h)\n","            loss = criterion(out, label.to(device).float())\n","\n","            # Perform backpropragation\n","            loss.backward()\n","            optimizer.step()\n","\n","            avg_loss += loss.item()\n","            if counter % print_every == 0:\n","                print(\n","                    f\"Epoch {epoch} - Step: {counter}/{len(train_loader)} - Average Loss for Epoch: {avg_loss/counter}\"\n","                )\n","        current_time = time.process_time()\n","\n","        print(\n","            f\"Epoch {epoch}/{n_epochs} Done, Total Loss: {avg_loss/len(train_loader)}\"\n","        )\n","\n","        print(f\"Time Elapsed for Epoch: {current_time-start_time} seconds\")\n","\n","        epoch_times.append(current_time - start_time)\n","\n","    print(f\"Total Training Time: {sum(epoch_times)} seconds\")\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"9O9OTJdBOJH4"},"source":["## Training the GRU model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"erMh9C5POJH5","scrolled":true,"outputId":"be877e62-2e2c-448f-c086-4e1a9debc43a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Training of GRU model\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1024])) that is different to the input size (torch.Size([1024, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Step: 100/424 - Average Loss for Epoch: 0.029731472283601762\n","Epoch 1 - Step: 200/424 - Average Loss for Epoch: 0.02743233013898134\n"]}],"source":["# seq_len = 90  # (timestamps)\n","n_hidden = 256\n","n_layers = 2\n","n_epochs = 5\n","print_every = 100\n","lr = 0.001\n","gru_model = train(\n","    train_loader,\n","    learn_rate=lr,\n","    hidden_dim=n_hidden,\n","    n_layers=n_layers,\n","    n_epochs=n_epochs,\n","    model_type=\"GRU\",\n","    print_every=print_every,\n",")"]},{"cell_type":"markdown","metadata":{"id":"zY_FO1M4OJH5"},"source":["## Save the GRU model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wmdfQaFoOJH5"},"outputs":[],"source":["torch.save(gru_model.state_dict(), \"./models/gru_model.pt\")"]},{"cell_type":"markdown","metadata":{"id":"EP-XW3PoOJH6"},"source":["## Train and Save an LSTM model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mfXMyXhlOJH6"},"outputs":[],"source":["lstm_model = train(\n","    train_loader,\n","    learn_rate=lr,\n","    hidden_dim=n_hidden,\n","    n_layers=n_layers,\n","    n_epochs=n_epochs,\n","    model_type=\"LSTM\",\n","    print_every=print_every,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kWg6OXnIOJH6"},"outputs":[],"source":["torch.save(lstm_model.state_dict(), \"./models/lstm_model.pt\")"]},{"cell_type":"markdown","metadata":{"id":"fAdV08pqOJH6"},"source":["As we can see from the training time of both models, the GRU model is the clear winner in terms of speed, as we have mentioned earlier. The GRU finished 5 training epochs faster than the LSTM model."]},{"cell_type":"markdown","metadata":{"id":"rLmZf5s_OJH6"},"source":["# Evaluating models\n","#### __Note: Running the following codes needs at least 16GB of memory.__\n","Moving on to measuring the accuracy of both models, we'll now use our `evaluate()` function and test dataset."]},{"cell_type":"markdown","metadata":{"id":"yyRMX6b3OJH6"},"source":["## Load the GRU model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pgUjzUmzOJH6"},"outputs":[],"source":["# move device to cpu for evaluation to avoid GPU memory run\n","device = \"cpu\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ngeRfWWiOJH6"},"outputs":[],"source":["hidden_dim = 256\n","input_dim = 5\n","output_dim = 1\n","n_layers = 2\n","gru_model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n","gru_model.load_state_dict(torch.load(\"./models/gru_model.pt\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VmySk3gmOJH6"},"outputs":[],"source":["# Move the model to the appropriate device\n","gru_model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"F2MvuzdeOJH6"},"source":["## Load the LSTM model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0-1dcFHOJH7"},"outputs":[],"source":["hidden_dim = 256\n","input_dim = 5\n","output_dim = 1\n","n_layers = 2\n","lstm_model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n","lstm_model.load_state_dict(torch.load(\"./models/lstm_model.pt\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RrgLJNxYOJH7"},"outputs":[],"source":["# Move the model to the appropriate device\n","lstm_model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"BrRv3Uc_OJH7"},"source":["## Model Evaluation\n","\n","For the purpose of comparing the performance of both models as well, we'll being tracking the time it takes for the model to train and eventually comparing the final accuracy of both models on the test set. For our accuracy measure, we'll use ***Symmetric Mean Absolute Percentage Error (sMAPE)*** to evaluate the models. *sMAPE* is the sum of the **absolute difference** between the predicted and actual values divided by the average of the predicted and actual value, therefore giving a percentage measuring the amount of error.\n","\n","This is the formula for *sMAPE*:\n","\n","$sMAPE = \\frac{100%}{n} \\sum_{t=1}^n \\frac{|F_t - A_t|}{(|F_t + A_t|)/2}$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hj9wT9VqOJH7"},"outputs":[],"source":["def sMAPE(outputs, targets):\n","    sMAPE = (\n","        100\n","        / len(targets)\n","        * np.sum(np.abs(outputs - targets) / (np.abs(outputs + targets)) / 2)\n","    )\n","    return sMAPE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPgjyKRLOJH7"},"outputs":[],"source":["def evaluate(model, test_x, test_y, label_scalers):\n","    model.eval()\n","    outputs = []\n","    targets = []\n","    start_time = time.process_time()\n","    # get data of test data for each state\n","    for file in test_x.keys():\n","        inputs = torch.from_numpy(np.array(test_x[file]))\n","        labels = torch.from_numpy(np.array(test_y[file]))\n","\n","        h = model.init_hidden(inputs.shape[0])\n","\n","        # predict outputs\n","        with torch.no_grad():\n","            out, h = model(inputs.to(device).float(), h)\n","\n","        outputs.append(\n","            label_scalers[file]\n","            .inverse_transform(out.cpu().detach().numpy())\n","            .reshape(-1)\n","        )\n","\n","        targets.append(\n","            label_scalers[file].inverse_transform(labels.numpy()).reshape(-1)\n","        )\n","\n","    # Merge all files\n","    concatenated_outputs = np.concatenate(outputs)\n","    concatenated_targets = np.concatenate(targets)\n","\n","    print(f\"Evaluation Time: {time.process_time()-start_time}\")\n","    print(f\"sMAPE: {round(sMAPE(concatenated_outputs, concatenated_targets), 3)}%\")\n","\n","    # list of of targets/outputs for each state\n","    return outputs, targets, sMAPE"]},{"cell_type":"markdown","metadata":{"id":"c3JYZ9jaOJH7"},"source":["## Evaluate performance of GRU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4MNgPLc5OJH7"},"outputs":[],"source":["gru_outputs, targets, gru_sMAPE = evaluate(gru_model, test_x, test_y, label_scalers)"]},{"cell_type":"markdown","metadata":{"id":"4pui2vzZOJH7"},"source":["## Evaluate performance of LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VPHomDkrOJH7"},"outputs":[],"source":["lstm_outputs, targets, lstm_sMAPE = evaluate(lstm_model, test_x, test_y, label_scalers)"]},{"cell_type":"markdown","metadata":{"id":"tWRKP8bvOJH7"},"source":["While the GRU model may have made smaller errors and edged the LSTM model slightly in terms of performance accuracy, the difference is insignificant and thus inconclusive. There have been many other tests conducted by others comparing both these models but there has largely been no clear winner as to which is the better architecture overall."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UVmTRquuOJH7"},"outputs":[],"source":["len(\n","    gru_outputs\n",")  # list of predicted output file for each state (each element has a 1d array for that state)"]},{"cell_type":"markdown","metadata":{"id":"4DFAgo99OJH7"},"source":["# Some visualizations"]},{"cell_type":"markdown","metadata":{"id":"Bw8ayikMOJH8"},"source":["Lastly, let's do some visualizations on random sets of our predicted output vs the actual consumption data for some states."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZCQcjDUOJH8"},"outputs":[],"source":["states_list = list(test_x.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vohJexWcOJH8"},"outputs":[],"source":["states_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTDxZGnwOJH8"},"outputs":[],"source":["plt.figure(figsize=(14, 10))\n","plt.subplot(2, 2, 1)\n","plt.plot(gru_outputs[0][-100:], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n","plt.plot(\n","    lstm_outputs[0][-100:], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2\n",")\n","plt.plot(targets[0][-100:], color=\"b\", label=\"Actual\")\n","plt.ylabel(\"Energy Consumption (MW)\")\n","plt.title(f\"Energy Consumption for {states_list[0]} state\")\n","plt.legend()\n","\n","plt.subplot(2, 2, 2)\n","plt.plot(gru_outputs[1][-50:], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n","plt.plot(lstm_outputs[1][-50:], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n","plt.plot(targets[1][-50:], color=\"b\", label=\"Actual\")\n","plt.ylabel(\"Energy Consumption (MW)\")\n","plt.title(f\"Energy Consumption for {states_list[1]} state\")\n","plt.legend()\n","\n","plt.subplot(2, 2, 3)\n","plt.plot(gru_outputs[2][:50], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n","plt.plot(lstm_outputs[2][:50], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n","plt.plot(targets[2][:50], color=\"b\", label=\"Actual\")\n","plt.ylabel(\"Energy Consumption (MW)\")\n","plt.title(f\"Energy Consumption for {states_list[2]} state\")\n","plt.legend()\n","\n","plt.subplot(2, 2, 4)\n","plt.plot(gru_outputs[3][:100], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n","plt.plot(lstm_outputs[3][:100], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n","plt.plot(targets[3][:100], color=\"b\", label=\"Actual\")\n","plt.title(f\"Energy Consumption for {states_list[3]} state\")\n","plt.ylabel(\"Energy Consumption (MW)\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"80i7kVdiOJH8"},"source":["Looks like the models are largely successful in predicting the trends of energy consumption. While they may still get some changes wrong, such as delays in predicting a drop in consumption, the predictions follow very closely to the actual line on the test set. This is due to the nature of energy consumption data and the fact that there are patterns and cyclical changes that the model can account for. Tougher time-series prediction problems such as stock price prediction or sales volume prediction may have data that is largely random or doesn’t have predictable patterns, and in such cases, the accuracy will definitely be lower."]}],"metadata":{"colab":{"toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"ddc04c03ff4e4de7a40dd72f34038767":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8bc8ab39374442f79af3b19ae78d5ef1","IPY_MODEL_9ba64a65a8254c1f963b009e26df8b53","IPY_MODEL_4c0fc8a3e8034da0893c61cc079a9876"],"layout":"IPY_MODEL_3dcdfd7cc5a747d092e138b507deb73f"}},"8bc8ab39374442f79af3b19ae78d5ef1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23eda55a86eb4aeebd2f0ac5ba958bda","placeholder":"​","style":"IPY_MODEL_ec113ca6eca44a2686f42a4dfdd7a61f","value":"100%"}},"9ba64a65a8254c1f963b009e26df8b53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2085b993975b43f78679b984709fc531","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b873635ef01a4f418c75de31754dd5c4","value":5}},"4c0fc8a3e8034da0893c61cc079a9876":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2be872a600ca40af96c9c094d0cac129","placeholder":"​","style":"IPY_MODEL_a0c4f61fefba4d4293a8b2dd159dfa1a","value":" 5/5 [00:40&lt;00:00,  6.84s/it]"}},"3dcdfd7cc5a747d092e138b507deb73f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23eda55a86eb4aeebd2f0ac5ba958bda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec113ca6eca44a2686f42a4dfdd7a61f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2085b993975b43f78679b984709fc531":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b873635ef01a4f418c75de31754dd5c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2be872a600ca40af96c9c094d0cac129":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0c4f61fefba4d4293a8b2dd159dfa1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
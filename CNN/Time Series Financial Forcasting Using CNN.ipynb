{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyMvLVdQ5V776avHEk2mzL+S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Import Library**"],"metadata":{"id":"8oaG8vq9kMbd"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"T4Px54pNkLq0","executionInfo":{"status":"ok","timestamp":1713148652852,"user_tz":-420,"elapsed":4497,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"}}},"outputs":[],"source":["import os\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, f1_score, mean_absolute_error"]},{"cell_type":"markdown","source":["# **Load Dataset**"],"metadata":{"id":"GotOup7TngJK"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","import os\n","\n","# Tentukan direktori tempat Anda menyimpan data CSV\n","# DATADIR = 'lokasi_folder_data_csv'\n","TRAIN_TEST_CUTOFF = '2016-04-21'\n","TRAIN_VALID_RATIO = 0.75\n","\n","# Lokasi URL dataset di GitHub\n","dataset_urls = [\n","    'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/FinansialPrediction/Processed_DJI.csv',\n","    'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/FinansialPrediction/Processed_NASDAQ.csv',\n","    'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/FinansialPrediction/Processed_NYSE.csv',\n","    'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/FinansialPrediction/Processed_RUSSELL.csv',\n","    'https://raw.githubusercontent.com/arifadli/DatasetRepository/main/FinansialPrediction/Processed_SP.csv'\n","]\n","\n","# Membaca dataset dari URL dan menyimpannya dalam kamus\n","data = {}\n","for url in dataset_urls:\n","    name = os.path.splitext(os.path.basename(url))[0]  # Ambil nama dataset dari URL\n","    X = pd.read_csv(url, index_col=\"Date\", parse_dates=True)\n","    # Periksa apakah kolom \"Name\" ada dalam DataFrame X\n","    if \"Name\" in X.columns:\n","        del X[\"Name\"]  # Hapus kolom \"Name\"\n","    # Pra-pemrosesan dasar: ambil nama, klasifikasi\n","    cols = X.columns\n","    X[\"Target\"] = (X[\"Close\"].pct_change().shift(-1) > 0).astype(int)\n","    X.dropna(inplace=True)\n","    # Sesuaikan scaler standar menggunakan dataset pelatihan\n","    index = X.index[X.index < TRAIN_TEST_CUTOFF]\n","    index = index[:int(len(index) * TRAIN_VALID_RATIO)]\n","    scaler = StandardScaler().fit(X.loc[index, cols])\n","    # Simpan dataframe yang telah diubah skala\n","    X[cols] = scaler.transform(X[cols])\n","    data[name] = X"],"metadata":{"id":"bVHITh10njCD","executionInfo":{"status":"ok","timestamp":1713150419031,"user_tz":-420,"elapsed":3432,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# **Function Definition**"],"metadata":{"id":"JnxX7VMQpCKn"}},{"cell_type":"code","source":["def recall_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def precision_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","def f1macro(y_true, y_pred):\n","    f_pos = f1_m(y_true, y_pred)\n","    # negative version of the data and prediction\n","    f_neg = f1_m(1-y_true, 1-K.clip(y_pred,0,1))\n","    return (f_pos + f_neg)/2\n","\n","def cnnpred_2d(seq_len=60, n_features=82, n_filters=(8,8,8), droprate=0.1):\n","    \"2D-CNNpred model according to the paper\"\n","    model = Sequential([\n","        Input(shape=(seq_len, n_features, 1)),\n","        Conv2D(n_filters[0], kernel_size=(1, n_features), activation=\"relu\"),\n","        Conv2D(n_filters[1], kernel_size=(3,1), activation=\"relu\"),\n","        MaxPool2D(pool_size=(2,1)),\n","        Conv2D(n_filters[2], kernel_size=(3,1), activation=\"relu\"),\n","        MaxPool2D(pool_size=(2,1)),\n","        Flatten(),\n","        Dropout(droprate),\n","        Dense(1, activation=\"sigmoid\")\n","    ])\n","    return model\n","\n","def datagen(data, seq_len, batch_size, targetcol, kind):\n","    \"As a generator to produce samples for Keras model\"\n","    batch = []\n","    while True:\n","        # Pick one dataframe from the pool\n","        key = random.choice(list(data.keys()))\n","        df = data[key]\n","        input_cols = [c for c in df.columns if c != targetcol]\n","        index = df.index[df.index < TRAIN_TEST_CUTOFF]\n","        split = int(len(index) * TRAIN_VALID_RATIO)\n","        assert split > seq_len, \"Training data too small for sequence length {}\".format(seq_len)\n","        if kind == 'train':\n","            index = index[:split]   # range for the training set\n","        elif kind == 'valid':\n","            index = index[split:]   # range for the validation set\n","        else:\n","            raise NotImplementedError\n","        # Pick one position, then clip a sequence length\n","        while True:\n","            t = random.choice(index)     # pick one time step\n","            n = (df.index == t).argmax() # find its position in the dataframe\n","            if n-seq_len+1 < 0:\n","                continue # this sample is not enough for one sequence length\n","            frame = df.iloc[n-seq_len+1:n+1]\n","            batch.append([frame[input_cols].values, df.loc[t, targetcol]])\n","            break\n","        # if we get enough for a batch, dispatch\n","        if len(batch) == batch_size:\n","            X, y = zip(*batch)\n","            X, y = np.expand_dims(np.array(X), 3), np.array(y)\n","            yield X, y\n","            batch = []\n","\n","def testgen(data, seq_len, targetcol):\n","    \"Return array of all test samples\"\n","    batch = []\n","    for key, df in data.items():\n","        input_cols = [c for c in df.columns if c != targetcol]\n","        # find the start of test sample\n","        t = df.index[df.index >= TRAIN_TEST_CUTOFF][0]\n","        n = (df.index == t).argmax()\n","        # extract sample using a sliding window\n","        for i in range(n+1, len(df)+1):\n","            frame = df.iloc[i-seq_len:i]\n","            batch.append([frame[input_cols].values, frame[targetcol][-1]])\n","    X, y = zip(*batch)\n","    return np.expand_dims(np.array(X),3), np.array(y)"],"metadata":{"id":"_AIjb-R6pAum","executionInfo":{"status":"ok","timestamp":1713149803084,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# **Building Model**"],"metadata":{"id":"erGLyrREuVsc"}},{"cell_type":"code","source":["seq_len = 60\n","batch_size = 128\n","n_epochs = 20\n","n_features = 82\n","\n","# Produce CNNpred as a binary classification problem\n","model = cnnpred_2d(seq_len, n_features)\n","model.compile(optimizer=\"adam\", loss=\"mae\", metrics=[\"acc\", f1macro])\n","model.summary()  # print model structure to console\n","\n","# Set up callbacks and fit the model\n","# We use custom validation score f1macro() and hence monitor for \"val_f1macro\"\n","checkpoint_path = \"./cp2d-{epoch}-{val_f1macro:.2f}.h5\"\n","callbacks = [\n","    ModelCheckpoint(checkpoint_path,\n","                    monitor='val_f1macro', mode=\"max\",\n","                    verbose=0, save_best_only=True, save_weights_only=False, save_freq=\"epoch\")\n","]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lkc3SP11uYg3","executionInfo":{"status":"ok","timestamp":1713150464945,"user_tz":-420,"elapsed":706,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"}},"outputId":"6fbe6270-cebf-46c5-aafd-a37018e8727d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 60, 1, 8)          664       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 58, 1, 8)          200       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 29, 1, 8)          0         \n"," D)                                                              \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 27, 1, 8)          200       \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 13, 1, 8)          0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 104)               0         \n","                                                                 \n"," dropout (Dropout)           (None, 104)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 105       \n","                                                                 \n","=================================================================\n","Total params: 1169 (4.57 KB)\n","Trainable params: 1169 (4.57 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# **Model Evaluation**"],"metadata":{"id":"BZ737cdwuh2c"}},{"cell_type":"code","source":["model.fit(datagen(data, seq_len, batch_size, \"Target\", \"train\"),\n","          validation_data=datagen(data, seq_len, batch_size, \"Target\", \"valid\"),\n","          epochs=n_epochs, steps_per_epoch=400, validation_steps=10, verbose=1, callbacks=callbacks)\n","\n","# Prepare test data\n","test_data, test_target = testgen(data, seq_len, \"Target\")\n","\n","# Test the model\n","test_out = model.predict(test_data)\n","test_pred = (test_out > 0.5).astype(int)\n","print(\"accuracy:\", accuracy_score(test_pred, test_target))\n","print(\"MAE:\", mean_absolute_error(test_pred, test_target))\n","print(\"F1:\", f1_score(test_pred, test_target))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Z5qMPC3ulx3","executionInfo":{"status":"ok","timestamp":1713153453905,"user_tz":-420,"elapsed":2935596,"user":{"displayName":"Ari Fadli","userId":"05527030487879681721"}},"outputId":"ca46275d-8680-4da0-cccd-76a51b3970e8"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","400/400 [==============================] - 154s 372ms/step - loss: 0.4460 - acc: 0.5585 - f1macro: 0.3616 - val_loss: 0.4747 - val_acc: 0.5250 - val_f1macro: 0.3436\n","Epoch 2/20\n","  1/400 [..............................] - ETA: 4s - loss: 0.5107 - acc: 0.4844 - f1macro: 0.3263"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["400/400 [==============================] - 149s 373ms/step - loss: 0.3549 - acc: 0.6618 - f1macro: 0.5939 - val_loss: 0.4559 - val_acc: 0.5539 - val_f1macro: 0.5111\n","Epoch 3/20\n","  1/400 [..............................] - ETA: 4s - loss: 0.2914 - acc: 0.7344 - f1macro: 0.7116"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["400/400 [==============================] - 150s 375ms/step - loss: 0.2426 - acc: 0.7767 - f1macro: 0.7641 - val_loss: 0.4861 - val_acc: 0.5102 - val_f1macro: 0.4758\n","Epoch 4/20\n","400/400 [==============================] - 149s 372ms/step - loss: 0.2025 - acc: 0.8100 - f1macro: 0.8003 - val_loss: 0.5002 - val_acc: 0.5109 - val_f1macro: 0.4838\n","Epoch 5/20\n","400/400 [==============================] - 143s 360ms/step - loss: 0.1850 - acc: 0.8252 - f1macro: 0.8164 - val_loss: 0.4861 - val_acc: 0.5164 - val_f1macro: 0.4892\n","Epoch 6/20\n","400/400 [==============================] - 149s 374ms/step - loss: 0.1757 - acc: 0.8324 - f1macro: 0.8244 - val_loss: 0.4871 - val_acc: 0.5109 - val_f1macro: 0.4831\n","Epoch 7/20\n","400/400 [==============================] - 145s 364ms/step - loss: 0.1716 - acc: 0.8346 - f1macro: 0.8276 - val_loss: 0.4790 - val_acc: 0.5172 - val_f1macro: 0.4838\n","Epoch 8/20\n","400/400 [==============================] - 145s 363ms/step - loss: 0.1661 - acc: 0.8397 - f1macro: 0.8326 - val_loss: 0.4739 - val_acc: 0.5258 - val_f1macro: 0.5077\n","Epoch 9/20\n","400/400 [==============================] - 146s 365ms/step - loss: 0.1630 - acc: 0.8422 - f1macro: 0.8352 - val_loss: 0.4804 - val_acc: 0.5148 - val_f1macro: 0.4948\n","Epoch 10/20\n","400/400 [==============================] - 147s 369ms/step - loss: 0.1547 - acc: 0.8496 - f1macro: 0.8428 - val_loss: 0.4868 - val_acc: 0.5156 - val_f1macro: 0.4939\n","Epoch 11/20\n","400/400 [==============================] - 139s 349ms/step - loss: 0.1537 - acc: 0.8503 - f1macro: 0.8436 - val_loss: 0.4745 - val_acc: 0.5258 - val_f1macro: 0.5038\n","Epoch 12/20\n","400/400 [==============================] - 149s 374ms/step - loss: 0.1555 - acc: 0.8482 - f1macro: 0.8414 - val_loss: 0.5137 - val_acc: 0.4883 - val_f1macro: 0.4517\n","Epoch 13/20\n","400/400 [==============================] - 151s 379ms/step - loss: 0.1510 - acc: 0.8523 - f1macro: 0.8458 - val_loss: 0.4951 - val_acc: 0.5055 - val_f1macro: 0.4867\n","Epoch 14/20\n","400/400 [==============================] - 139s 348ms/step - loss: 0.1489 - acc: 0.8542 - f1macro: 0.8479 - val_loss: 0.4582 - val_acc: 0.5445 - val_f1macro: 0.5231\n","Epoch 15/20\n","  7/400 [..............................] - ETA: 3s - loss: 0.1331 - acc: 0.8694 - f1macro: 0.8585"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["400/400 [==============================] - 152s 381ms/step - loss: 0.1478 - acc: 0.8553 - f1macro: 0.8488 - val_loss: 0.4850 - val_acc: 0.5094 - val_f1macro: 0.4898\n","Epoch 16/20\n","400/400 [==============================] - 139s 348ms/step - loss: 0.1471 - acc: 0.8557 - f1macro: 0.8495 - val_loss: 0.4882 - val_acc: 0.5109 - val_f1macro: 0.4904\n","Epoch 17/20\n","400/400 [==============================] - 154s 385ms/step - loss: 0.1429 - acc: 0.8605 - f1macro: 0.8550 - val_loss: 0.4675 - val_acc: 0.5336 - val_f1macro: 0.5106\n","Epoch 18/20\n","400/400 [==============================] - 138s 347ms/step - loss: 0.1445 - acc: 0.8584 - f1macro: 0.8526 - val_loss: 0.4722 - val_acc: 0.5266 - val_f1macro: 0.5082\n","Epoch 19/20\n","400/400 [==============================] - 155s 388ms/step - loss: 0.1359 - acc: 0.8668 - f1macro: 0.8615 - val_loss: 0.4682 - val_acc: 0.5336 - val_f1macro: 0.5044\n","Epoch 20/20\n","400/400 [==============================] - 138s 347ms/step - loss: 0.1415 - acc: 0.8613 - f1macro: 0.8558 - val_loss: 0.4840 - val_acc: 0.5227 - val_f1macro: 0.5044\n","33/33 [==============================] - 0s 3ms/step\n","accuracy: 0.5170731707317073\n","MAE: 0.48292682926829267\n","F1: 0.6292134831460674\n"]}]}]}